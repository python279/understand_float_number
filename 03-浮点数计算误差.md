# 3 浮点数计算为什么有误差

理解了浮点数的表示方法后，我们现在要面对浮点数计算中最核心的问题：**为什么会有误差？** 这与整数的精确性形成鲜明对比。

## 3.1 误差的根本原因

### 3.1.1 有限精度表示

浮点数的核心问题是**有限精度**：

- **整数**：每个整数都有精确的二进制表示
- **浮点数**：只能表示有限数量的数值，其他数值必须近似

例如，在float32中：
- 尾数只有23位（加上隐含位共24位）
- 只能精确表示2²⁴个不同的尾数值
- 超出这个范围的数值必须舍入

### 3.1.2 舍入误差

IEEE 754标准定义了四种舍入模式：

1. **Round to nearest, ties to even (RNTE)**：舍入到最接近，在一样接近的情况下偶数优先（Ties To Even，这是默认的舍入方式）：会将结果舍入为最接近且可以表示的值，但是当存在两个数一样接近的时候，则取其中的偶数（在二进制中是以 0 结尾的）。

2. **Round toward positive infinity (RTPI)**：朝 +∞ 方向舍入：会将结果朝正无限大的方向舍入。

3. **Round toward negative infinity (RTNI)**：朝 -∞ 方向舍入：会将结果朝负无限大的方向舍入。

4. **Round toward zero (RTZ)**：朝 0 方向舍入：会将结果朝 0 的方向舍入。

**示例**：在float32中表示0.1

0.1的精确二进制表示（无限循环）：
```
0.1 = 0.0001100110011001100110011001100110011001100110011001101...
```

由于float32只能存储24位尾数，不同舍入模式会产生不同的结果：

| 舍入模式 | 舍入后的二进制 | 尾数值 | 指数 | 十进制结果 | 绝对误差 |
|---------|---------------|--------|------|------------|----------|
| **Round to nearest, ties to even (RNTE)** | `0.00011001100110011001101` | 1.60000002384185791015625 | 2⁻⁴ | 0.100000001490116119384765625 | 1.49 × 10⁻⁹ |
| **Round toward positive infinity (RTPI)** | `0.00011001100110011001101` | 1.60000002384185791015625 | 2⁻⁴ | 0.100000001490116119384765625 | 1.49 × 10⁻⁹ |
| **Round toward negative infinity (RTNI)** | `0.00011001100110011001100` | 1.599999904632568359375 | 2⁻⁴ | 0.0999999940395355224609375 | -5.96 × 10⁻⁹ |
| **Round toward zero (RTZ)** | `0.00011001100110011001100` | 1.599999904632568359375 | 2⁻⁴ | 0.0999999940395355224609375 | -5.96 × 10⁻⁹ |

**说明**：
- 0.1的二进制表示是无限循环小数
- float32的尾数精度限制导致必须舍入
- 不同舍入模式产生不同的近似值
- 默认的RNTE模式通常产生最小的误差

## 3.2 常见误差场景

### 3.2.1 加法误差

**大数加小数**

```python
# 大数 + 小数 的问题
a = 1e16
b = 1.0
result = a + b

# 理论上：1e16 + 1 = 10000000000000001
# 实际结果：1e16 (精度丢失)
```

**原因分析**：

**二进制推算过程**：

1. **1e16的二进制表示**：
   - 十进制：10000000000000000
   - 二进制：1000110110000110101111000100000000000000000000000
   - IEEE 754 (float64)：
     - 符号位：0（正数）
     - 指数：1077 (十进制) = 10000110101 (二进制)，偏移量为1023
     - 尾数：1.0001101100001101011110001 (隐含的1.)

2. **1.0的二进制表示**：
   - 十进制：1.0
   - 二进制：1.0
   - IEEE 754 (float64)：
     - 符号位：0（正数）
     - 指数：1023 (十进制) = 01111111111 (二进制)，偏移量为1023
     - 尾数：1.0 (隐含的1.)

3. **对齐过程**：
   - 指数差：1077 - 1023 = 54
   - 需要将1.0的尾数右移54位进行对齐
   - 1.0右移54位后：0.000000000000000000000000000000000000000000000000000001
   - 由于float64只有52位尾数精度，右移54位后超出了精度范围

4. **实际计算**：
   - 对齐后的1.0变为0（因为超出了尾数精度）
   - 1e16 + 0 = 1e16
   - 结果仍然是1e16，1.0完全被忽略

**精度丢失的数学解释**

在float64中：
- 尾数精度：53位
- 1e16 ≈ 2⁵³
- 1.0 = 2⁰
- 对齐后：1.0的尾数右移53位，变为0

### 3.2.2 减法误差（灾难性抵消）

**相近数相减**

```python
# 灾难性抵消示例
a = 1.23456789
b = 1.23456788
result = a - b

# 理论上：0.00000001
# 实际结果：0
```

1.2345789 = 0 01111111 00111100000011010101110

1.2345678 = 0 01111111 00111100000011010101110

1.2345789 - 1.2345788 = 0

实际结果（float64）：

1.2345789 =             0 01111111111 0011110000001101010111001101111111010100111001110101

1.2345678 =             0 01111111111 0011110000001101010110110011001001010101101111011010

1.2345789 - 1.2345788 = 0 01111100100 0101011110011000111011100000000000000000000000000000 = 9.99999993922529e-09

**误差放大**：
- 相对误差 = |实际值 - 理论值| / |理论值|
- 当理论值很小时，相对误差被放大
- 这就是"灾难性抵消"

### 3.2.3 乘法误差

**精度累积**

```python
# 连续乘法误差累积
x = 0.1
result = 1.0

for i in range(10):
    result *= x

# 理论上：0.1¹⁰ = 1e-10
# 实际结果：1.0000000000000006e-10
```

**溢出和下溢**

```python
# 溢出示例
a = 1e308
b = 1e308
result = a * b  # 产生inf

# 下溢示例
a = 1e-308
b = 1e-308
result = a * b  # 可能产生0或次正规数
```

### 3.2.4 除法误差

**精度损失**

```python
# 大数除以小数
a = 1e256
b = 1e-256
result = a / b

# 超出float64的范围，产生inf
```

## 3.3 误差的数学分析

### 3.3.1 机器精度（Machine Epsilon）

| 格式 | 尾数位宽（不含隐含位） | 公式 | ε（十进制近似） |
|---|---|---|---|
| **float32** | 23 | ε = 2⁻²³ | 1.19 × 10⁻⁷ |
| **float64** | 52 | ε = 2⁻⁵² | 2.22 × 10⁻¹⁶ |
| **fp8e4m3** | 3  | ε = 2⁻³  | 0.125 |

**含义**  
任意实数 x 经格式化后，相对误差上限为  
```math
\frac{|x - \hat{x}|}{|x|} \le \varepsilon
```

### 3.3.2 浮点数误差的衡量方法

**绝对误差与相对误差**

**绝对误差**：实际值与理论值的差的绝对值
```math
\text{绝对误差} = |x - \hat{x}|
```

**相对误差**：绝对误差与理论值的比值
```math
\text{相对误差} = \frac{|x - \hat{x}|}{|x|}
```

**实际应用示例**：
```python
def calculate_errors(theoretical, actual):
    """计算绝对误差和相对误差"""
    absolute_error = abs(actual - theoretical)
    relative_error = absolute_error / abs(theoretical) if theoretical != 0 else float('inf')
    
    return absolute_error, relative_error

# 示例：计算0.1的表示误差
theoretical = 0.1
actual = 0.100000001490116119384765625  # float32中的0.1

abs_err, rel_err = calculate_errors(theoretical, actual)
print(f"绝对误差: {abs_err}")
print(f"相对误差: {rel_err:.2e}")
```

**ULP（Unit in the Last Place）**

**ULP定义**：两个相邻浮点数之间的最小差值，即浮点数表示中的最小单位。

**ULP的重要性**：
- ULP是浮点数精度的自然单位
- 误差用ULP表示比用绝对误差更准确
- 不同数量级的数，1 ULP的绝对大小不同

**为什么1 ULP的绝对大小会变化？**

这是由浮点数的指数-尾数表示法决定的。对于float32，在指数为 `e` 的区间内：
```math
1 ULP = 2^{(e-23)}
```

**不同数量级的ULP大小对比**：

| 数量级范围 | 指数值(e) | 1 ULP的绝对大小 | 示例数值 | 相对精度 |
|------------|-----------|----------------|----------|----------|
| [0.5, 1) | -1 | 2^(-24) ≈ 5.96×10^(-8) | 0.5 | ~1.19×10^(-7) |
| [1, 2) | 0 | 2^(-23) ≈ 1.19×10^(-7) | 1.0 | ~1.19×10^(-7) |
| [2, 4) | 1 | 2^(-22) ≈ 2.38×10^(-7) | 2.0 | ~1.19×10^(-7) |
| [4, 8) | 2 | 2^(-21) ≈ 4.77×10^(-7) | 4.0 | ~1.19×10^(-7) |
| [1024, 2048) | 10 | 2^(-13) ≈ 1.22×10^(-4) | 1024.0 | ~1.19×10^(-7) |

**关键洞察**：
- 虽然ULP的**绝对大小**随数量级呈指数增长
- 但**相对精度**（ULP/数值本身）在所有数量级下大致相同
- 这确保了浮点数在不同范围内都能提供一致的相对精度

**为什么ULP比绝对误差更有意义？**

考虑两个计算误差：
- 1.0的结果偏差1×10^(-7) → 约1 ULP
- 1024.0的结果偏差1×10^(-4) → 约1 ULP

用绝对误差看差异巨大，但用ULP衡量精度相当，这更符合浮点数的实际表示能力。

**ULP计算**：
```python
import math
import struct
import sys

def ulp_float32(x):
    """计算float32精度下x处的ULP值"""
    if x == 0:
        return 2**(-149)  # 最小次正规数
    
    # 获取下一个可表示的浮点数
    x_bits = struct.unpack('!I', struct.pack('!f', abs(x)))[0]
    next_x_bits = x_bits + 1
    next_x = struct.unpack('!f', struct.pack('!I', next_x_bits))[0]
    
    # ULP是当前值与下一个可表示值之间的差
    return next_x - abs(x)

def ulp_error(actual, expected, precision='float64'):
    """计算误差的ULP数"""
    if precision == 'float32':
        ulp_value = ulp_float32(expected)
    else:  # float64 - 使用内置的math.ulp函数
        import math
        ulp_value = math.ulp(expected) if expected != 0 else math.ulp(1.0)
    
    absolute_error = abs(actual - expected)
    ulp_count = absolute_error / ulp_value
    
    return ulp_count

# 示例1: float64精度
import math
x = 1.0
print(f"1.0处的ULP (float64): {math.ulp(x):.2e}")
print(f"下一个可表示的数: {x + math.ulp(x)}")

# 示例2: float32中0.1的表示和ULP误差
from decimal import Decimal, getcontext
getcontext().prec = 50  # 设置高精度

# 真正的理论值 (精确的 1/10)
theoretical_01_exact = Decimal('0.1')
actual_f32_01 = struct.unpack('f', struct.pack('f', 0.1))[0]  # float32实际值

print(f"\n0.1在float32中的表示:")
print(f"理论值(精确): {theoretical_01_exact}")
print(f"float32实际值: {actual_f32_01:.25f}")

# 计算float32中0.1的ULP误差
ulp_value_f32 = ulp_float32(actual_f32_01)
# 使用高精度计算误差，避免精度损失
absolute_error_f32 = float(abs(theoretical_01_exact - Decimal(str(actual_f32_01))))
ulp_count_f32 = absolute_error_f32 / ulp_value_f32

print(f"\nfloat32中0.1的ULP分析:")
print(f"绝对误差: {absolute_error_f32:.2e}")
print(f"ULP值: {ulp_value_f32:.2e}")
print(f"ULP误差: {ulp_count_f32:.2f} ULP")
```

**预期输出**：
```
1.0处的ULP (float64): 2.22e-16
下一个可表示的数: 1.0000000000000002

0.1在float32中的表示:
理论值(精确): 0.1
float32实际值: 0.1000000014901161193847656

float32中0.1的ULP分析:
绝对误差: 1.49e-09
ULP值: 7.45e-09
ULP误差: 0.20 ULP
```

**不同误差衡量方法的比较**

| 误差类型 | 定义 | 优点 | 缺点 | 适用场景 |
|---------|------|------|------|----------|
| **绝对误差** | \|x - x̂\| | 直观易懂 | 不能反映相对大小 | 固定精度要求 |
| **相对误差** | \|x - x̂\|/\|x\| | 标准化，可比较 | 对接近0的值敏感 | 一般精度分析 |
| **ULP误差** | \|x - x̂\|/ULP(x) | 浮点数自然单位 | 概念相对复杂 | 浮点算法验证 |

**ULP误差的优势**：
1. **标准化**：不同数量级的数可以用相同的ULP标准
2. **精度相关**：ULP与浮点数的实际精度直接相关
3. **算法验证**：常用于验证浮点算法的正确性

**实际应用示例**：
```python
def validate_float_algorithm(func, test_cases, max_ulp_error=1.0):
    """验证浮点算法的ULP误差"""
    results = []
    
    for x, expected in test_cases:
        actual = func(x)
        ulp_count = ulp_error(actual, expected)
        results.append({
            'input': x,
            'expected': expected,
            'actual': actual,
            'ulp_error': ulp_count,
            'passed': ulp_count <= max_ulp_error
        })
    
    return results

# 测试sin函数的精度
import math
test_cases = [
    (0.0, 0.0),
    (math.pi/2, 1.0),
    (math.pi, 0.0),
    (math.pi*3/2, -1.0)
]

# 定义一个简单的自定义sin函数用于测试
def my_sin(x):
    """简单的sin近似计算，用于演示ULP误差"""
    # 使用泰勒级数前几项计算sin
    if abs(x) < 1e-10:
        return x  # 小角度近似
    
    # 故意引入可测量的误差
    return math.sin(x) * (1 + 1e-14)  # 增大误差量级

# 修正后的测试用例
better_test_cases = [
    (0.0, 0.0),
    (0.5, math.sin(0.5)),
    (1.0, math.sin(1.0)),
    (1.5, math.sin(1.5))
]

# 测试我们的自定义函数与标准库函数的ULP误差
# 由于我们引入了误差(1e-14)，应该能观察到可测量的ULP误差
results = validate_float_algorithm(my_sin, better_test_cases, max_ulp_error=2.0)
for result in results:
    status = "✓" if result['passed'] else "✗"
    print(f"{status} x={result['input']:.2f}, ULP误差={result['ulp_error']:.2f}")

# 注意：ULP误差的大小取决于:
# 1. 引入的误差大小
# 2. 当前数值大小下的ULP值（不同数量级的数，1 ULP的绝对大小不同）
# 3. 舍入方式和浮点表示的特性
#
# 为什么1e-16的误差没有被测量到？
# - 对于sin(0.5)≈0.479这样的值，其ULP大约是2^(-53)≈1.11e-16
# - 当引入的误差(1e-16)小于ULP时，在浮点表示中会被完全舍入掉
# - 增大误差到1e-14后，它大于ULP值，因此可以被测量到
```

## 3.6 小结

### 浮点数误差的核心原因

1. **有限精度**：无法表示所有实数
2. **舍入误差**：超出精度的数值必须舍入  
3. **误差传播**：运算过程中误差累积
4. **算法敏感性**：某些计算对误差极其敏感

### 关键概念

**机器精度（Machine Epsilon）**：
- float32: ε ≈ 1.19×10⁻⁷
- float64: ε ≈ 2.22×10⁻¹⁶

**误差衡量标准**：
- **绝对误差**：|x - x̂|，直观但不适合比较不同数量级
- **相对误差**：|x - x̂|/|x|，标准化但对接近0的值敏感
- **ULP误差**：以浮点数自然单位衡量，最适合算法验证

**ULP特性**：不同数量级的数，1 ULP的绝对大小不同，但相对精度一致。

### 实用策略

1. **避免问题运算**：大数加小数、相近数相减
2. **选择稳定算法**：Kahan求和、数值稳定的公式变换
3. **合理精度要求**：算法验证通常要求 < 1-2 ULP
4. **充分测试**：边界值、特殊值、误差累积场景

### 核心理念

浮点数虽然不如整数"听话"，但通过理解其特性、量化误差、选择合适算法，我们可以在实际应用中可靠地使用浮点数计算。

---

**下一章**：[参考资料](./04-参考资料.md)
